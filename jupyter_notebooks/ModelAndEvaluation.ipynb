{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 2:\n",
        "    * Develop a machine learning model for automating image categorization, leveraging CNN architecture for efficient and scalable classification.\n",
        "\n",
        "* Answer Business Requirement 3:\n",
        "    * Evaluate the model's performance by assessing its accuracy and loss metrics.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cifar10_dataset_small/train\n",
        "* inputs/cifar10_dataset_small/validation\n",
        "* inputs/cifar10_dataset_small/test\n",
        "* image shape embeddings\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Class distribution plots for training, validation, and test sets.\n",
        "* Image augmentation\n",
        "* Development and training of the machine learning model\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation saved as a pickle file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from matplotlib.image import imread\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change and Set directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('New folder: ' + current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input directories and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_root_dir = 'inputs/cifar10_dataset_small'\n",
        "train_path = dataset_root_dir + '/train'\n",
        "validation_path = dataset_root_dir + '/validation'\n",
        "test_path = dataset_root_dir + '/test'\n",
        "train_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v7'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print(f'Version {version} is already available.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n",
        "    print(f'New directory for version {version} has been created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "labels.sort()\n",
        "print(\"Class names:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Distribution in Train, Test and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's recap on the plot from the previous notebook:\n",
        "- The dataset is a subset and contains 5000 images divided into Test, Train and Validation sets.\n",
        "- Train set containing 70% of the images - 350 images in each class\n",
        "- Test set containing 20% of the images - 100 images in each class\n",
        "- Validation set containing 10% of the images - 50 images in each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from source.data_management import load_pkl_file\n",
        "\n",
        "\n",
        "def count_images_in_path(path):\n",
        "    \"\"\"\n",
        "    Counts the number of images in each class folder within the given path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The directory path containing subfolders for each class.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are class labels (subfolder names)\n",
        "        and values are the number of images in each class.\n",
        "    \n",
        "    \"\"\"\n",
        "    class_counts = {}\n",
        "\n",
        "    for label in os.listdir(path):\n",
        "        label_path = os.path.join(path, label)\n",
        "        class_counts[label] = len(os.listdir(label_path))  \n",
        "    return class_counts\n",
        "\n",
        "# Count images in datasets\n",
        "train_counts = count_images_in_path(train_path)\n",
        "validation_counts = count_images_in_path(validation_path)\n",
        "test_counts = count_images_in_path(test_path)\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "train_df = pd.DataFrame(list(train_counts.items()), columns=['Class', 'Train'])\n",
        "validation_df = pd.DataFrame(list(validation_counts.items()), columns=['Class','Validation'])\n",
        "test_df = pd.DataFrame(list(test_counts.items()), columns=['Class', 'Test'])\n",
        "\n",
        "# Merge dataframes for visualization\n",
        "df = pd.merge(train_df, validation_df, on='Class')\n",
        "df = pd.merge(df, test_df, on='Class')\n",
        "\n",
        "df.set_index('Class').plot(kind='bar', figsize=(12, 6))\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images per Class in Train, Validation, and Test Sets')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Train set counts: {train_counts}\")\n",
        "print(f\"Validation set counts: {validation_counts}\")\n",
        "print(f\"Test set counts: {test_counts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize image data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set this to False to skip augmentation for the first model training\n",
        "use_augmentation = True\n",
        "\n",
        "if use_augmentation:\n",
        "    # Use image augmentation\n",
        "    augmented_image_data = ImageDataGenerator(\n",
        "                            rotation_range=15,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            zoom_range=[0.8, 1.2],\n",
        "                            horizontal_flip=True,\n",
        "                            rescale=1./255\n",
        "    )\n",
        "else:\n",
        "    # Only normalize the images, no augmentation\n",
        "    augmented_image_data = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment training, validation and test image datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Prepare the training set\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "# Validation and Test sets always just normalized, no augmentation\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training set\n",
        "for _ in range(3):\n",
        "    img, label = train_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation set\n",
        "for _ in range(3):\n",
        "    img, label = validation_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n",
        "\n",
        "# Test set\n",
        "for _ in range(3):\n",
        "    img, label = test_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class indicies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=image_shape, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "create_tf_model().summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Model For Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "model = create_tf_model()\n",
        "history = model.fit(train_set,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch=train_set.samples // batch_size,\n",
        "                    validation_data=validation_set,\n",
        "                    callbacks=[\n",
        "                        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
        "                        EarlyStopping(monitor='val_loss', patience=15)\n",
        "                    ],\n",
        "                    verbose=1\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(f'{file_path}/snapsort_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(f'{file_path}/snapsort_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f'{file_path}/evaluation.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Confusion Matrix & Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions as probabilities\n",
        "predictions = model.predict(test_set)\n",
        "# Convert probabilities to class labels\n",
        "y_pred = predictions.argmax(axis=1)\n",
        "# Actual labels\n",
        "y_true = test_set.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict On New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load a random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66\n",
        "label = labels[0]\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convert image to array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Predict class for the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict probabilities\n",
        "pred_proba = model.predict(my_image)[0]\n",
        "\n",
        "# Map indices to class names\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_class_index = np.argmax(pred_proba)\n",
        "pred_class = target_map[predicted_class_index]\n",
        "\n",
        "print(\"Predicted Probabilities:\", pred_proba)\n",
        "print(\"Predicted Class:\", pred_class)\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=(7, 6), gridspec_kw={'height_ratios': [3, 1]})\n",
        "\n",
        "# Display the input image\n",
        "axs[0].imshow(pil_image)\n",
        "axs[0].set_title('Input Image')\n",
        "axs[0].axis('off')\n",
        "\n",
        "# Plot the prediction probabilities\n",
        "axs[1].bar(range(len(labels)), pred_proba, color='skyblue')\n",
        "axs[1].set_title('Prediction Probabilities')\n",
        "axs[1].set_xlabel('Classes')\n",
        "axs[1].set_ylabel('Probability')\n",
        "\n",
        "# Show all class labels\n",
        "axs[1].set_xticks(range(len(labels)))\n",
        "axs[1].set_xticklabels(labels, rotation=90)\n",
        "\n",
        "# Add the probability value next to the bar for the predicted class\n",
        "axs[1].text(predicted_class_index, pred_proba[predicted_class_index] + 0.01, \n",
        "            f'{pred_proba[predicted_class_index]:.2f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Push Files To Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add to gitignore:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View changed files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add, commit and push your files to the repo (all or single files):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add .\n",
        "\n",
        "!git commit -m \"Message\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Evolution:**\n",
        "\n",
        "| Model Version | Augmented Data | Epochs | Train Accuracy | Validation Accuracy | Test Accuracy | Test Loss | Time per Epoch | Total Training Time | Trainable Parameters | Model Size |\n",
        "|---|---|---|---|---|---|---|---|---|---|---|\n",
        "| v1 | No | 18 | 73.54% | 56.00% | 50.00% | X.XXXX | 5 seconds | 90 seconds (1.5 minutes) | 90,506 | 0.36 MB |\n",
        "| v1.5 | Yes | 15 | 39.60% | 39.40% | 40.90% | 1.5921 | 5 seconds | 75 seconds (1.25 minutes) | 90,506 | 0.36 MB |\n",
        "| v2 | No | 25 | 70.26% | 51.60% | 50.90% | 1.5637 | 5 seconds | 125 seconds (2.08 minutes) | 90,506 | 0.36 MB |\n",
        "| v3 | Yes | 21 | 70.26% | 51.60% | 43.40% | 1.5835 | 5 seconds | 105 seconds (1.75 minutes) | 147,978 | 0.59 MB |\n",
        "| v4 | No | 25 | 89.63% | 54.20% | 49.60% | 2.1050 | 16 seconds | 400 seconds (6.67 minutes) | 587,914 | 2.35 MB |\n",
        "| v5 | No | 50 | 100% | 62.60% | 62.60% | 1.3020 | 15-16 seconds | 800 seconds (13.3 minutes) | 587,914 | 2.35 MB |\n",
        "| v6 | Yes | 50 | 91.15% | 69.00% | 67.20% | 1.1917 | 16-17 seconds | 800 seconds (13.3 minutes) | 587,914 | 2.35 MB |\n",
        "| v7 | Yes | 64 (early stop) | 92.45% | 73.00% | 71.20% | 1.2812 | 25 seconds | 2,500 seconds (42 minutes) | 2,604,810 | 2.35 MB |\n",
        "\n",
        "This table summarizes the performance of each model version, highlighting the evolution of the model over time and the impact of different techniques like data augmentation. \n",
        "\n",
        "**Analysis:**\n",
        "\n",
        "*   **Model v1:**  Without data augmentation, the model achieved an accuracy of 50.00%, indicating a need for improvement. \n",
        "*   **Model v1.5:**  While using data augmentation, the model's performance worsened, suggesting the need to explore more complex model architectures.\n",
        "*   **Model v2:**  Adding a convolutional layer and batch normalization improved accuracy to 50.90%. \n",
        "*   **Model v3:**  Continuing with data augmentation, the model's performance again declined, implying that the model may be struggling with overfitting. \n",
        "*   **Model v4:**  Increasing the number of filters and adding regularization techniques (L2 regularization) to the dense layer resulted in increased accuracy, suggesting that regularization helps prevent overfitting. \n",
        "*   **Model v5:**  Adding max pooling layers and increasing model complexity significantly improved accuracy to 62.60%. \n",
        "*   **Model v6:** Data augmentation further improved accuracy, reaching 67.20%, confirming the hypothesis that data augmentation improves model generalization.\n",
        "*   **Final Model v7:** The final model (v7) incorporates data augmentation and achieved a test accuracy of 71.20%, exceeding the business criteria of 70% accuracy. \n",
        "\n",
        "**Conclusion:** \n",
        "\n",
        "Through a process of model evolution, involving architecture adjustments and data augmentation, the final model (v7) achieved the desired 70% accuracy.  The confusion matrix and classification report indicate that the model is performing well for some categories but struggles with others.  To further improve performance, the model's ability to differentiate between visually similar categories should be addressed.  \n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "- **Data Augmentation:** Explore more advanced augmentation techniques (e.g., color shifting, blurring) to create even greater variations in training data.\n",
        "- **Model Architecture:** Research more sophisticated architectures, such as ResNet or VGG, for potentially higher accuracy.\n",
        "- **Hyperparameter Tuning:**  Conduct more systematic hyperparameter tuning to optimize model settings.\n",
        "- **Class Weights:**  Investigate the use of class weights to improve the model's performance on classes that are difficult to classify."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

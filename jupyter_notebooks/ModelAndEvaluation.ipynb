{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 2:\n",
        "    * Develop a machine learning model for automating image categorization, leveraging CNN architecture for efficient and scalable classification.\n",
        "\n",
        "* Answer Business Requirement 3:\n",
        "    * Evaluate the model's performance by assessing its accuracy and loss metrics.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cifar10_dataset_small/train\n",
        "* inputs/cifar10_dataset_small/validation\n",
        "* inputs/cifar10_dataset_small/test\n",
        "* image shape embeddings\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Class distribution plots for training, validation, and test sets.\n",
        "* Image augmentation\n",
        "* Development and training of the machine learning model\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation saved as a pickle file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from matplotlib.image import imread\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change and Set directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('New folder: ' + current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input directories and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_root_dir = 'inputs/cifar10_dataset_small'\n",
        "train_path = dataset_root_dir + '/train'\n",
        "validation_path = dataset_root_dir + '/validation'\n",
        "test_path = dataset_root_dir + '/test'\n",
        "train_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v7'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print(f'Version {version} is already available.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n",
        "    print(f'New directory for version {version} has been created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "labels.sort()\n",
        "print(\"Class names:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Distribution in Train, Test and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's recap on the plot from the previous notebook:\n",
        "- The dataset is a subset and contains 5000 images divided into Test, Train and Validation sets.\n",
        "- Train set containing 70% of the images - 350 images in each class\n",
        "- Test set containing 20% of the images - 100 images in each class\n",
        "- Validation set containing 10% of the images - 50 images in each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from source.data_management import load_pkl_file\n",
        "\n",
        "\n",
        "def count_images_in_path(path):\n",
        "    \"\"\"\n",
        "    Counts the number of images in each class folder within the given path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The directory path containing subfolders for each class.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are class labels (subfolder names)\n",
        "        and values are the number of images in each class.\n",
        "    \n",
        "    \"\"\"\n",
        "    class_counts = {}\n",
        "\n",
        "    for label in os.listdir(path):\n",
        "        label_path = os.path.join(path, label)\n",
        "        class_counts[label] = len(os.listdir(label_path))  \n",
        "    return class_counts\n",
        "\n",
        "# Count images in datasets\n",
        "train_counts = count_images_in_path(train_path)\n",
        "validation_counts = count_images_in_path(validation_path)\n",
        "test_counts = count_images_in_path(test_path)\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "train_df = pd.DataFrame(list(train_counts.items()), columns=['Class', 'Train'])\n",
        "validation_df = pd.DataFrame(list(validation_counts.items()), columns=['Class','Validation'])\n",
        "test_df = pd.DataFrame(list(test_counts.items()), columns=['Class', 'Test'])\n",
        "\n",
        "# Merge dataframes for visualization\n",
        "df = pd.merge(train_df, validation_df, on='Class')\n",
        "df = pd.merge(df, test_df, on='Class')\n",
        "\n",
        "df.set_index('Class').plot(kind='bar', figsize=(12, 6))\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images per Class in Train, Validation, and Test Sets')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Train set counts: {train_counts}\")\n",
        "print(f\"Validation set counts: {validation_counts}\")\n",
        "print(f\"Test set counts: {test_counts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize image data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set this to False to skip augmentation for the first model training\n",
        "use_augmentation = True\n",
        "\n",
        "if use_augmentation:\n",
        "    # Use image augmentation\n",
        "    augmented_image_data = ImageDataGenerator(\n",
        "                            rotation_range=15,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            zoom_range=[0.8, 1.2],\n",
        "                            horizontal_flip=True,\n",
        "                            rescale=1./255\n",
        "    )\n",
        "else:\n",
        "    # Only normalize the images, no augmentation\n",
        "    augmented_image_data = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment training, validation and test image datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Prepare the training set\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "# Validation and Test sets always just normalized, no augmentation\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training set\n",
        "for _ in range(3):\n",
        "    img, label = train_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation set\n",
        "for _ in range(3):\n",
        "    img, label = validation_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n",
        "\n",
        "# Test set\n",
        "for _ in range(3):\n",
        "    img, label = test_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class indicies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=image_shape, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "create_tf_model().summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Model For Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "model = create_tf_model()\n",
        "history = model.fit(train_set,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch=train_set.samples // batch_size,\n",
        "                    validation_data=validation_set,\n",
        "                    callbacks=[\n",
        "                        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
        "                        EarlyStopping(monitor='val_loss', patience=15)\n",
        "                    ],\n",
        "                    verbose=1\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(f'{file_path}/snapsort_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(f'{file_path}/snapsort_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f'{file_path}/evaluation.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Confusion Matrix & Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions as probabilities\n",
        "predictions = model.predict(test_set)\n",
        "# Convert probabilities to class labels\n",
        "y_pred = predictions.argmax(axis=1)\n",
        "# Actual labels\n",
        "y_true = test_set.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict On New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load a random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66\n",
        "label = labels[0]\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convert image to array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Predict class for the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict probabilities\n",
        "pred_proba = model.predict(my_image)[0]\n",
        "\n",
        "# Map indices to class names\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_class_index = np.argmax(pred_proba)\n",
        "pred_class = target_map[predicted_class_index]\n",
        "\n",
        "print(\"Predicted Probabilities:\", pred_proba)\n",
        "print(\"Predicted Class:\", pred_class)\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=(7, 6), gridspec_kw={'height_ratios': [3, 1]})\n",
        "\n",
        "# Display the input image\n",
        "axs[0].imshow(pil_image)\n",
        "axs[0].set_title('Input Image')\n",
        "axs[0].axis('off')\n",
        "\n",
        "# Plot the prediction probabilities\n",
        "axs[1].bar(range(len(labels)), pred_proba, color='skyblue')\n",
        "axs[1].set_title('Prediction Probabilities')\n",
        "axs[1].set_xlabel('Classes')\n",
        "axs[1].set_ylabel('Probability')\n",
        "\n",
        "# Show all class labels\n",
        "axs[1].set_xticks(range(len(labels)))\n",
        "axs[1].set_xticklabels(labels, rotation=90)\n",
        "\n",
        "# Add the probability value next to the bar for the predicted class\n",
        "axs[1].text(predicted_class_index, pred_proba[predicted_class_index] + 0.01, \n",
        "            f'{pred_proba[predicted_class_index]:.2f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Push Files To Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add to gitignore:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View changed files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add, commit and push your files to the repo (all or single files):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add .\n",
        "\n",
        "!git commit -m \"Message\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model v1:** (Without augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately X.XX%\n",
        "- **Final Test Loss:** X.XXXX\n",
        "\n",
        "**Summary:**\n",
        "- **Training Accuracy (after 18 epochs):** Approximately 73.54%\n",
        "- **Validation Accuracy (after 18 epochs):** Approximately 56.00%\n",
        "- **Test Accuracy:** Approximately 50.00% \n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 5 seconds\n",
        "- **Total Time for 18 Epochs:** 90 seconds (or about 1.5 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 32 → 64 → 64\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 90,506\n",
        "- **Model Size:** \n",
        "  - 90,506 params × 4 bytes/param = 362,024 bytes ≈ 0.36 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model v1.5:** (With augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately 40.90%\n",
        "- **Final Test Loss:** 1.5921\n",
        "\n",
        " **Summary:**\n",
        "- **Training Accuracy (after 15 epochs):** Approximately 39.60%\n",
        "- **Validation Accuracy (after 15 epochs):** Approximately 39.40%\n",
        "- **Test Accuracy:** Approximately 40.90%\n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 5 seconds\n",
        "- **Total Time for 15 Epochs:** 75 seconds (or about 1.25 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 32 → 64 → 64\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 90,506\n",
        "- **Model Size:** \n",
        "  - 90,506 params × 4 bytes/param = 362,024 bytes ≈ 0.36 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model v2:** (Without augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately 50.90%\n",
        "- **Final Test Loss:** 1.5637\n",
        "\n",
        "**Summary:**\n",
        "- **Training Accuracy (after 25 epochs):** Approximately 70.26%\n",
        "- **Validation Accuracy (after 25 epochs):** Approximately 51.60%\n",
        "- **Test Accuracy:** Approximately 50.90%\n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 5 seconds\n",
        "- **Total Time for 25 Epochs:** 5 seconds/epoch × 25 epochs = 125 seconds (or about 2.08 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 32 → 64 → 64 → 128 (with Batch Normalization)\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 90,506\n",
        "- **Model Size:** \n",
        "  - 90,506 params × 4 bytes/param = 362,024 bytes ≈ 0.36 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model v3:** (With augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately 43.40%\n",
        "- **Final Test Loss:** 1.5835\n",
        "\n",
        "**Summary:**\n",
        "- **Training Accuracy (after 21 epochs):** Approximately 70.26%\n",
        "- **Validation Accuracy (after 21 epochs):** Approximately 51.60%\n",
        "- **Test Accuracy:** Approximately 43.40%\n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 5 seconds\n",
        "- **Total Time for 21 Epochs:** 5 seconds/epoch × 21 epochs = 105 seconds (or about 1.75 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 32 → 64 → 64 → 128 (with Batch Normalization)\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 147,978\n",
        "- **Model Size:** \n",
        "  - 147,978 params × 4 bytes/param = 591,912 bytes ≈ 0.59 MB\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model v4:** (Without augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately 49.60%\n",
        "- **Final Test Loss:** 2.1050\n",
        "\n",
        "**Summary:**\n",
        "- **Training Accuracy (after 25 epochs):** Approximately 89.63%\n",
        "- **Validation Accuracy (after 25 epochs):** Approximately 54.20%\n",
        "- **Test Accuracy:** Approximately 49.60%\n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 16 seconds\n",
        "- **Total Time for 25 Epochs:** 16 seconds/epoch × 25 epochs = 400 seconds (or about 6.67 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 64 → 128 → 128 → 256 (with Batch Normalization)\n",
        "- **L2 Regularization:** Applied to the dense layer with a regularization strength of 0.01.\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 587,914\n",
        "- **Model Size:** \n",
        "  - 587,914 params × 4 bytes/param = 2,351,656 bytes ≈ 2.35 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model v5:** (Without augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately 62.60%\n",
        "- **Final Test Loss:** 1.3020\n",
        "\n",
        "**Summary:**\n",
        "- **Training Accuracy (after 50 epochs):** Approximately 100%\n",
        "- **Validation Accuracy (after 50 epochs):** Approximately 62.60%\n",
        "- **Test Accuracy:** Approximately 62.60%\n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 15–16 seconds\n",
        "- **Total Time for 50 Epochs:** 16 seconds/epoch × 50 epochs = 800 seconds (or about 13.3 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 64 → 128 → 128 → 256 (with Batch Normalization)\n",
        "- **MaxPooling:** Applied after every second Conv2D layer\n",
        "- **L2 Regularization:** Applied to the dense layer with a regularization strength of 0.01\n",
        "- **Dropout:** Rate = 0.5 (to prevent overfitting)\n",
        "- **Dense Layer:** Units → 512 (with L2 Regularization)\n",
        "- **Output Layer:** Dense → 10 units (softmax activation for classification)\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 587,914\n",
        "- **Non-Trainable Parameters:** 1,152\n",
        "- **Model Size:**\n",
        "  - 587,914 params × 4 bytes/param = 2,351,656 bytes ≈ 2.35 MB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model v6** (With augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately 67.20%\n",
        "- **Final Test Loss:** 1.1917\n",
        "\n",
        "**Summary:**\n",
        "- **Training Accuracy (after 50 epochs):** Approximately 91.15%\n",
        "- **Validation Accuracy (after 50 epochs):** Approximately 69.00%\n",
        "- **Test Accuracy:** Approximately 67.20%\n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 16-17 seconds\n",
        "- **Total Time for 50 Epochs:** 16 seconds/epoch × 50 epochs = 800 seconds (or about 13.3 minutes)\n",
        "\n",
        "**Data Augmentation:**\n",
        "- **Rotation Range:** 15°\n",
        "- **Width/Height Shift:** 5%\n",
        "- **Zoom Range:** 0.8 to 1.2\n",
        "- **Horizontal Flip:** Enabled\n",
        "- **Rescale:** 1./255 (image normalization)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 64 → 128 → 128 → 256 (with Batch Normalization)\n",
        "- **L2 Regularization:** Applied to the dense layer with a regularization strength of 0.01.\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 587,914\n",
        "- **Model Size:** \n",
        "  - 587,914 params × 4 bytes/param = 2,351,656 bytes ≈ 2.35 MB\n",
        "  \n",
        "---\n",
        "\n",
        "**Note:**\n",
        "The model achieved a **5% increase in accuracy** on the test set (from 62.60% to 67.20%) when using data augmentation. This supports the hypothesis that **data augmentation improves model generalization** and enhances performance by introducing variability in the training dataset.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Final Model v7:** (With augmented data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Performance on Test Set\n",
        "- **Final Test Accuracy:** Approximately 71.20%\n",
        "- **Final Test Loss:** 1.2812\n",
        "\n",
        "### Summary\n",
        "- **Training Accuracy (after 64/100 epochs):** Approximately 92.45%\n",
        "- **Validation Accuracy (after 64/100 epochs):** Approximately 73.00%\n",
        "- **Test Accuracy:** Approximately 71.20%\n",
        "\n",
        "### Training Time\n",
        "- **Time per Epoch:** Approximately 25 seconds\n",
        "- **Total Time for 64/100 Epochs:** 2,500 seconds (about 42 minutes)\n",
        "\n",
        "### Training Summary\n",
        "- **Total Epochs:** 100 (early stop = 64)\n",
        "- **Early Stopping Patience:** 15 epochs without improvement on validation loss\n",
        "- **Learning Rate Reduction:** Reduced by a factor of 0.2 after 5 epochs without improvement on validation loss\n",
        "\n",
        "### Data Augmentation\n",
        "- **Rotation Range:** 15°\n",
        "- **Width/Height Shift:** 5%\n",
        "- **Zoom Range:** 0.8 to 1.2\n",
        "- **Horizontal Flip:** Enabled\n",
        "- **Rescale:** 1./255 (image normalization)\n",
        "\n",
        "### Model Architecture\n",
        "- **Conv2D Layers:** \n",
        "  - 1st Layer: 64 filters\n",
        "  - 2nd Layer: 128 filters\n",
        "  - 3rd Layer: 256 filters\n",
        "- **Batch Normalization:** Applied after each convolutional layer.\n",
        "- **Max Pooling Layers:** 3 pooling layers to reduce dimensionality.\n",
        "- **Dense Layer:** 512 units in the dense layer.\n",
        "\n",
        "### Model Summary\n",
        "- **Total Parameters:** 2,607,242\n",
        "- **Trainable Parameters:** 2,604,810\n",
        "- **Non-trainable Parameters:** 2,432\n",
        "\n",
        "#### **Note:** The Model met the business criteria of 70% accuracy!\n",
        "Further training can be done to improve performance, but the model has already achieved the target.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 2:\n",
        "    * Develop a machine learning model for automating image categorization, leveraging CNN architecture for efficient and scalable classification.\n",
        "\n",
        "* Answer Business Requirement 3:\n",
        "    * Assess model performance using accuracy, precision, recall, F1-score, and a confusion matrix to ensure high accuracy and effectiveness in predictions.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cifar10_dataset_small/train\n",
        "* inputs/cifar10_dataset_small/validation\n",
        "* inputs/cifar10_dataset_small/test\n",
        "* image shape embeddings\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Class distribution plots for training, validation, and test sets.\n",
        "* Image augmentation\n",
        "* Development and training of the machine learning model\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation saved as a pickle file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from matplotlib.image import imread\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change and Set directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('New folder: ' + current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input directories and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_root_dir = 'inputs/cifar10_dataset_small'\n",
        "train_path = dataset_root_dir + '/train'\n",
        "validation_path = dataset_root_dir + '/validation'\n",
        "test_path = dataset_root_dir + '/test'\n",
        "train_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1.5'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print(f'Version {version} is already available.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n",
        "    print(f'New directory for version {version} has been created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "labels.sort()\n",
        "print(\"Class names:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Distribution in Train, Test and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's recap on the plot from the previous notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images_in_path(path):\n",
        "    \"\"\"\n",
        "    Counts the number of images in each class folder within the given path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The directory path containing subfolders for each class.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are class labels (subfolder names) and values are the number of images in each class.\n",
        "    \n",
        "    \"\"\"\n",
        "    class_counts = {}\n",
        "    for label in labels:\n",
        "        label_path = os.path.join(path, label)\n",
        "        class_counts[label] = len(os.listdir(label_path))\n",
        "    return class_counts\n",
        "\n",
        "# Count images in datasets\n",
        "train_counts = count_images_in_path(train_path)\n",
        "validation_counts = count_images_in_path(validation_path)\n",
        "test_counts = count_images_in_path(test_path)\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "train_df = pd.DataFrame(list(train_counts.items()), columns=['Class', 'Train'])\n",
        "validation_df = pd.DataFrame(list(validation_counts.items()), columns=['Class', 'Validation'])\n",
        "test_df = pd.DataFrame(list(test_counts.items()), columns=['Class', 'Test'])\n",
        "\n",
        "# Merge dataframes for visualization\n",
        "df = pd.merge(train_df, validation_df, on='Class')\n",
        "df = pd.merge(df, test_df, on='Class')\n",
        "\n",
        "df.set_index('Class').plot(kind='bar', figsize=(12, 6))\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images per Class in Train, Validation, and Test Sets')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize image data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set this to False to skip augmentation for the first model training\n",
        "use_augmentation = True\n",
        "\n",
        "if use_augmentation:\n",
        "    # Use image augmentation\n",
        "    augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                              width_shift_range=0.10,\n",
        "                                              height_shift_range=0.10,\n",
        "                                              shear_range=0.1,\n",
        "                                              zoom_range=0.1,\n",
        "                                              horizontal_flip=True,\n",
        "                                              vertical_flip=True,\n",
        "                                              fill_mode='nearest',\n",
        "                                              rescale=1./255)\n",
        "else:\n",
        "    # Only normalize the images, no augmentation\n",
        "    augmented_image_data = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment training, validation and test image datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 20\n",
        "\n",
        "# Prepare the training set\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "# Validation and Test sets always just normalized, no augmentation\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training set\n",
        "for _ in range(3):\n",
        "    img, label = train_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation set\n",
        "for _ in range(3):\n",
        "    img, label = validation_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n",
        "\n",
        "# Test set\n",
        "for _ in range(3):\n",
        "    img, label = test_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class indicies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "              activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "              activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "create_tf_model().summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Model For Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(f'{file_path}/snapsort_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(f'{file_path}/snapsort_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f'{file_path}/evaluation.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict On New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load a random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66\n",
        "label = labels[0]\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convert image to array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Predict class for the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict probabilities\n",
        "pred_proba = model.predict(my_image)[0]\n",
        "\n",
        "# Map indices to class names\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_class_index = np.argmax(pred_proba)\n",
        "pred_class = target_map[predicted_class_index]\n",
        "\n",
        "print(\"Predicted Probabilities:\", pred_proba)\n",
        "print(\"Predicted Class:\", pred_class)\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=(7, 6), gridspec_kw={'height_ratios': [3, 1]})\n",
        "\n",
        "# Display the input image\n",
        "axs[0].imshow(pil_image)\n",
        "axs[0].set_title('Input Image')\n",
        "axs[0].axis('off')\n",
        "\n",
        "# Plot the prediction probabilities\n",
        "axs[1].bar(range(len(labels)), pred_proba, color='skyblue')\n",
        "axs[1].set_title('Prediction Probabilities')\n",
        "axs[1].set_xlabel('Classes')\n",
        "axs[1].set_ylabel('Probability')\n",
        "\n",
        "# Show all class labels\n",
        "axs[1].set_xticks(range(len(labels)))\n",
        "axs[1].set_xticklabels(labels, rotation=90)\n",
        "\n",
        "# Add the probability value next to the bar for the predicted class\n",
        "axs[1].text(predicted_class_index, pred_proba[predicted_class_index] + 0.01, \n",
        "            f'{pred_proba[predicted_class_index]:.2f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Push Files To Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add to gitignore:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View changed files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add, commit and push your files to the repo (all or single files):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add .\n",
        "\n",
        "!git commit -m \"feat: Train and evaluate v1.5 model\" -m \"apply augmented images and decrease accuracy of model\"\n",
        "\n",
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model v1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately X.XX% *(Insert actual test accuracy here)*\n",
        "- **Final Test Loss:** X.XXXX *(Insert actual test loss here)*\n",
        "\n",
        "**Summary:**\n",
        "- **Training Accuracy (after 18 epochs):** Approximately 73.54%\n",
        "- **Validation Accuracy (after 18 epochs):** Approximately 56.00%\n",
        "- **Test Accuracy:** Approximately X.XX% \n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 5 seconds\n",
        "- **Total Time for 18 Epochs:** 90 seconds (or about 1.5 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 32 → 64 → 64\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 90,506\n",
        "- **Model Size:** \n",
        "  - 90,506 params × 4 bytes/param = 362,024 bytes ≈ 0.36 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model v1.5:** (With augmented images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Performance on Test Set:**\n",
        "- **Final Test Accuracy:** Approximately 40.90%\n",
        "- **Final Test Loss:** 1.5921\n",
        "\n",
        " **Summary:**\n",
        "- **Training Accuracy (after 15 epochs):** Approximately 39.60%\n",
        "- **Validation Accuracy (after 15 epochs):** Approximately 39.40%\n",
        "- **Test Accuracy:** Approximately 40.90%\n",
        "\n",
        "**Training Time:**\n",
        "- **Time per Epoch:** Approximately 5 seconds\n",
        "- **Total Time for 15 Epochs:** 75 seconds (or about 1.25 minutes)\n",
        "\n",
        "**Model Architecture:**\n",
        "- **Conv2D Layers:** Filters → 32 → 64 → 64\n",
        "\n",
        "**Model Summary:**\n",
        "- **Trainable Parameters:** 90,506\n",
        "- **Model Size:** \n",
        "  - 90,506 params × 4 bytes/param = 362,024 bytes ≈ 0.36 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
